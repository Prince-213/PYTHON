{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/CODE/PYTHON/Auto-Eye-Data/thermal/flir_cars_people_on_road.avif\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ALCS BONNY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\tkinter\\__init__.py\", line 1885, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\customtkinter\\windows\\widgets\\ctk_button.py\", line 554, in _clicked\n",
      "    self._command()\n",
      "  File \"C:\\Users\\ALCS BONNY\\AppData\\Local\\Temp\\ipykernel_10012\\4093031894.py\", line 87, in filedetect\n",
      "    results = model([path], save=True, show=True, conf=0.55, iou=0.4)\n",
      "  File \"c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\ultralytics\\engine\\model.py\", line 102, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\ultralytics\\engine\\model.py\", line 275, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 204, in __call__\n",
      "    return list(self.stream_inference(source, model, *args, **kwargs))  # merge list of Result into one\n",
      "  File \"c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 254, in stream_inference\n",
      "    self.setup_source(source if source is not None else self.args.source)\n",
      "  File \"c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 228, in setup_source\n",
      "    self.dataset = load_inference_source(\n",
      "  File \"c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\ultralytics\\data\\build.py\", line 166, in load_inference_source\n",
      "    source, webcam, screenshot, from_img, in_memory, tensor = check_source(source)\n",
      "  File \"c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\ultralytics\\data\\build.py\", line 141, in check_source\n",
      "    source = autocast_list(source)  # convert all list elements to PIL or np arrays\n",
      "  File \"c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\ultralytics\\data\\loaders.py\", line 497, in autocast_list\n",
      "    files.append(Image.open(requests.get(im, stream=True).raw if str(im).startswith(\"http\") else im))\n",
      "  File \"c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\PIL\\Image.py\", line 3309, in open\n",
      "    raise UnidentifiedImageError(msg)\n",
      "PIL.UnidentifiedImageError: cannot identify image file 'C:/CODE/PYTHON/Auto-Eye-Data/thermal/flir_cars_people_on_road.avif'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\PIL\\Image.py\", line 3251, in open\n",
      "    fp.seek(0)\n",
      "AttributeError: 'str' object has no attribute 'seek'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ALCS BONNY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\tkinter\\__init__.py\", line 1885, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\customtkinter\\windows\\widgets\\ctk_button.py\", line 554, in _clicked\n",
      "    self._command()\n",
      "  File \"C:\\Users\\ALCS BONNY\\AppData\\Local\\Temp\\ipykernel_10012\\4093031894.py\", line 87, in filedetect\n",
      "    results = model([path], save=True, show=True, conf=0.55, iou=0.4)\n",
      "  File \"c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\ultralytics\\engine\\model.py\", line 102, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\ultralytics\\engine\\model.py\", line 275, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 204, in __call__\n",
      "    return list(self.stream_inference(source, model, *args, **kwargs))  # merge list of Result into one\n",
      "  File \"c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 254, in stream_inference\n",
      "    self.setup_source(source if source is not None else self.args.source)\n",
      "  File \"c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 228, in setup_source\n",
      "    self.dataset = load_inference_source(\n",
      "  File \"c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\ultralytics\\data\\build.py\", line 166, in load_inference_source\n",
      "    source, webcam, screenshot, from_img, in_memory, tensor = check_source(source)\n",
      "  File \"c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\ultralytics\\data\\build.py\", line 141, in check_source\n",
      "    source = autocast_list(source)  # convert all list elements to PIL or np arrays\n",
      "  File \"c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\ultralytics\\data\\loaders.py\", line 497, in autocast_list\n",
      "    files.append(Image.open(requests.get(im, stream=True).raw if str(im).startswith(\"http\") else im))\n",
      "  File \"c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\PIL\\Image.py\", line 3253, in open\n",
      "    fp = io.BytesIO(fp.read())\n",
      "AttributeError: 'str' object has no attribute 'read'\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "import customtkinter\n",
    "from PIL import Image, ImageTk\n",
    "import threading\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from tkinter import filedialog as fd\n",
    "\n",
    "\n",
    "class App(customtkinter.CTk):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model1 = YOLO('./myset/best.pt')\n",
    "        # model2 = YOLO('yolov8n-seg.pt')\n",
    "\n",
    "        # Define the video files for the trackers\n",
    "        self.video_file1 = 0  # Path to video file, 0 for webcam\n",
    "        self.video_file2 = 1  # Path to video file, 0 for webcam, 1 for external camera\n",
    "\n",
    "        self.tracker_thread1 = threading.Thread(target=self.run_tracker_in_thread, args=(\n",
    "            self.video_file1, self.model1, 1), daemon=True)\n",
    "\n",
    "        img = tk.PhotoImage(file='./network-eye-in-a-frame.png')\n",
    "        self.iconphoto(False, img)\n",
    "        self.title(\"Eye Disease Detection App\")\n",
    "\n",
    "        self.geometry(\"600x500\")\n",
    "        self.grid_columnconfigure((0, 1), weight=1)\n",
    "\n",
    "        self.gap = customtkinter.CTkLabel(self, text=\"\", font=(\n",
    "            \"Arial\", 24, 'bold'), fg_color=\"transparent\")\n",
    "        self.gap.grid(row=0, column=1, padx=20,  sticky=\"ew\", columnspan=2)\n",
    "\n",
    "        self.label = customtkinter.CTkLabel(self, text=\"INSURGENCY SURVEILLANCE AND DOMAIN LOCALIZATION USING CARBON TRACKING AND DEEP LEARNING TECHNIQUE\", font=(\n",
    "            \"Arial\", 22, 'bold'),  fg_color=\"transparent\", justify=\"center\", wraplength=400)\n",
    "        self.label.grid(row=1, column=1, padx=60, pady=20,\n",
    "                        sticky=\"ew\", columnspan=2)\n",
    "\n",
    "        self.my_image = customtkinter.CTkImage(light_image=Image.open(\n",
    "            \"./network-eye-in-a-frame.png\"), dark_image=Image.open(\"./network-eye-in-a-frame.png\"), size=(80, 80))\n",
    "\n",
    "        self.image_label = customtkinter.CTkLabel(\n",
    "            self, image=self.my_image, text=\"\")  # display image with a CTkLabel\n",
    "        self.image_label.grid(row=2, column=0, padx=20,\n",
    "                              pady=20, sticky=\"ew\", columnspan=2)\n",
    "\n",
    "        # display image with a CTkLabel\n",
    "\n",
    "        self.button = customtkinter.CTkButton(\n",
    "            self, text=\"START REALTIME DETECTION\", height=50,  font=(\"Arial\", 18, 'bold'),  command=self.run)\n",
    "        self.button.grid(row=3, column=0, padx=20, pady=20,\n",
    "                         sticky=\"ew\", columnspan=2)\n",
    "\n",
    "        self.button2 = customtkinter.CTkButton(self, text=\"SELECT IMAGE TO DETECT\", height=50,  font=(\n",
    "            \"Arial\", 18, 'bold'),  command=self.filedetect)\n",
    "        self.button2.grid(row=4, column=0, padx=20, pady=20,\n",
    "                          sticky=\"ew\", columnspan=2)\n",
    "        # self.checkbox_1 = customtkinter.CTkCheckBox(self, text=\"checkbox 1\")\n",
    "        # self.checkbox_1.grid(row=1, column=0, padx=20, pady=(0, 20), sticky=\"w\")\n",
    "        # self.checkbox_2 = customtkinter.CTkCheckBox(self, text=\"checkbox 2\")\n",
    "        # self.checkbox_2.grid(row=1, column=1, padx=20, pady=(0, 20), sticky=\"w\")\n",
    "\n",
    "        \"\"\" self.courtsey = customtkinter.CTkLabel(\n",
    "            self, text=\"Author: Ilo Chinonyelum\", font=(\"Arial\", 18, ), fg_color=\"transparent\")\n",
    "        self.courtsey.grid(row=5, column=0, padx=20,\n",
    "                           pady=20, sticky=\"ew\", columnspan=2)\n",
    " \"\"\"\n",
    "    def select_file(self):\n",
    "        filetypes = (\n",
    "            ('pic files', '*.jpg'),\n",
    "        )\n",
    "\n",
    "        filename = fd.askopenfilename(\n",
    "            title='Open a file',\n",
    "            initialdir='/',\n",
    "            filetypes=filetypes)\n",
    "\n",
    "        print(filename)\n",
    "        return filename\n",
    "\n",
    "    def filedetect(self):\n",
    "        path = self.select_file()\n",
    "\n",
    "        model = YOLO('./thermal.pt')\n",
    "\n",
    "        results = model([path], save=True, show=True, conf=0.55, iou=0.4)\n",
    "\n",
    "        for result in results:\n",
    "            boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "            masks = result.masks  # Masks object for segmentation masks outputs\n",
    "            keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "            probs = result.probs  # Probs object for classification outputs\n",
    "            result.filname = 'result.jpg'\n",
    "            print(result.path)  # display to screen\n",
    "\n",
    "    # Create the tracker threads\n",
    "\n",
    "    # tracker_thread2 = threading.Thread(target=run_tracker_in_thread, args=(video_file2, model2, 2), daemon=True)\n",
    "\n",
    "    # Start the tracker threads\n",
    "\n",
    "    # tracker_thread2.start()\n",
    "\n",
    "    # Wait for the tracker threads to finish\n",
    "    # tracker_thread1.join()\n",
    "    # tracker_thread2.join()\n",
    "\n",
    "    def run(self):\n",
    "        self.tracker_thread1.start()\n",
    "        self.tracker_thread1.join()\n",
    "\n",
    "    def button_callback(self):\n",
    "        print(\"button pressed\")\n",
    "\n",
    "    def run_tracker_in_thread(self, filename, model, file_index):\n",
    "        \"\"\"\n",
    "        Runs a video file or webcam stream concurrently with the YOLOv8 model using threading.\n",
    "\n",
    "        This function captures video frames from a given file or camera source and utilizes the YOLOv8 model for object\n",
    "        tracking. The function runs in its own thread for concurrent processing.\n",
    "\n",
    "        Args:\n",
    "            filename (str): The path to the video file or the identifier for the webcam/external camera source.\n",
    "            model (obj): The YOLOv8 model object.\n",
    "            file_index (int): An index to uniquely identify the file being processed, used for display purposes.\n",
    "\n",
    "        Note:\n",
    "            Press 'q' to quit the video display window.\n",
    "        \"\"\"\n",
    "        video = cv2.VideoCapture(filename)  # Read the video file\n",
    "\n",
    "        width, height = 1024, 720\n",
    "\n",
    "# Set the width and height\n",
    "        video.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "        video.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "\n",
    "        while True:\n",
    "            ret, frame = video.read()  # Read the video frames\n",
    "\n",
    "            # Exit the loop if no more frames in either video\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Track objects in frames if available\n",
    "            results = model.track(frame, persist=True, conf=0.43)\n",
    "            res_plotted = results[0].plot()\n",
    "            cv2.imshow(f\"Tracking_Stream_{file_index}\", res_plotted)\n",
    "\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "\n",
    "        # Release video sources\n",
    "        video.release()\n",
    "\n",
    "\n",
    "app = App()\n",
    "app.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
