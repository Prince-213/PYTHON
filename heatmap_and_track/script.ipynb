{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading people-walking.mp4 assets \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;163;81;251m██████████\u001b[0m| 7.25M/7.25M [00:04<00:00, 1.87MB/s]\n",
      "usage: ipykernel_launcher.py [-h] --source_weights_path SOURCE_WEIGHTS_PATH\n",
      "                             [--source_video_path SOURCE_VIDEO_PATH]\n",
      "                             [--target_video_path TARGET_VIDEO_PATH]\n",
      "                             [--confidence_threshold CONFIDENCE_THRESHOLD]\n",
      "                             [--iou_threshold IOU_THRESHOLD]\n",
      "                             [--heatmap_alpha HEATMAP_ALPHA] [--radius RADIUS]\n",
      "                             [--track_threshold TRACK_THRESHOLD]\n",
      "                             [--track_seconds TRACK_SECONDS]\n",
      "                             [--match_threshold MATCH_THRESHOLD]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --source_weights_path\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\CODE\\PYTHON\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3558: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import supervision as sv\n",
    "from supervision.assets import VideoAssets, download_assets\n",
    "\n",
    "\n",
    "def download_video() -> str:\n",
    "    download_assets(VideoAssets.PEOPLE_WALKING)\n",
    "    return VideoAssets.PEOPLE_WALKING.value\n",
    "\n",
    "\n",
    "def heatmap_and_track(\n",
    "    source_weights_path: str,\n",
    "    source_video_path: str,\n",
    "    target_video_path: str,\n",
    "    confidence_threshold: float = 0.35,\n",
    "    iou_threshold: float = 0.5,\n",
    "    heatmap_alpha: float = 0.5,\n",
    "    radius: int = 25,\n",
    "    track_threshold: float = 0.35,\n",
    "    track_seconds: int = 5,\n",
    "    match_threshold: float = 0.99,\n",
    ") -> None:\n",
    "    # instantiate model\n",
    "    model = YOLO(source_weights_path)\n",
    "\n",
    "    # heatmap config\n",
    "    heat_map_annotator = sv.HeatMapAnnotator(\n",
    "        position=sv.Position.BOTTOM_CENTER,\n",
    "        opacity=heatmap_alpha,\n",
    "        radius=radius,\n",
    "        kernel_size=25,\n",
    "        top_hue=0,\n",
    "        low_hue=125,\n",
    "    )\n",
    "\n",
    "    # annotation config\n",
    "    label_annotator = sv.LabelAnnotator(text_position=sv.Position.CENTER)\n",
    "\n",
    "    # get the video fps\n",
    "    cap = cv2.VideoCapture(source_video_path)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    cap.release()\n",
    "\n",
    "    # tracker config\n",
    "    byte_tracker = sv.ByteTrack(\n",
    "        track_thresh=track_threshold,\n",
    "        track_buffer=track_seconds * fps,\n",
    "        match_thresh=match_threshold,\n",
    "        frame_rate=fps,\n",
    "    )\n",
    "\n",
    "    # video config\n",
    "    video_info = sv.VideoInfo.from_video_path(video_path=source_video_path)\n",
    "    frames_generator = sv.get_video_frames_generator(\n",
    "        source_path=source_video_path, stride=1\n",
    "    )\n",
    "\n",
    "    # Detect, track, annotate, save\n",
    "    with sv.VideoSink(target_path=target_video_path, video_info=video_info) as sink:\n",
    "        for frame in frames_generator:\n",
    "            result = model(\n",
    "                source=frame,\n",
    "                classes=[0],  # only person class\n",
    "                conf=confidence_threshold,\n",
    "                iou=iou_threshold,\n",
    "                # show_conf = True,\n",
    "                # save_txt = True,\n",
    "                # save_conf = True,\n",
    "                # save = True,\n",
    "                # use None = CPU, 0 = single GPU, or [0,1] = dual GPU\n",
    "                device=None,\n",
    "            )[0]\n",
    "\n",
    "            detections = sv.Detections.from_ultralytics(\n",
    "                result)  # get detections\n",
    "\n",
    "            detections = byte_tracker.update_with_detections(\n",
    "                detections\n",
    "            )  # update tracker\n",
    "\n",
    "            # draw heatmap\n",
    "            annotated_frame = heat_map_annotator.annotate(\n",
    "                scene=frame.copy(), detections=detections\n",
    "            )\n",
    "\n",
    "            # draw other attributes from `detections` object\n",
    "            labels = [\n",
    "                f\"#{tracker_id}\"\n",
    "                for class_id, tracker_id in zip(\n",
    "                    detections.class_id, detections.tracker_id\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            label_annotator.annotate(\n",
    "                scene=annotated_frame, detections=detections, labels=labels\n",
    "            )\n",
    "\n",
    "            sink.write_frame(frame=annotated_frame)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Heatmap and Tracking with Supervision\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--source_weights_path\",\n",
    "        required=True,\n",
    "        help=\"Path to the source weights file\",\n",
    "        type=str,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--source_video_path\",\n",
    "        default=download_video(),\n",
    "        help=\"Path to the source video file\",\n",
    "        type=str,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--target_video_path\",\n",
    "        default=\"output.mp4\",\n",
    "        help=\"Path to the target video file (output)\",\n",
    "        type=str,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--confidence_threshold\",\n",
    "        default=0.35,\n",
    "        help=\"Confidence threshold for the model\",\n",
    "        type=float,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--iou_threshold\",\n",
    "        default=0.5,\n",
    "        help=\"IOU threshold for the model\",\n",
    "        type=float,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--heatmap_alpha\",\n",
    "        default=0.5,\n",
    "        help=\"Opacity of the overlay mask, between 0 and 1\",\n",
    "        type=float,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--radius\",\n",
    "        default=25,\n",
    "        help=\"Radius of the heat circle\",\n",
    "        type=float,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--track_threshold\",\n",
    "        default=0.35,\n",
    "        help=\"Detection confidence threshold for track activation\",\n",
    "        type=float,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--track_seconds\",\n",
    "        default=5,\n",
    "        help=\"Number of seconds to buffer when a track is lost\",\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--match_threshold\",\n",
    "        default=0.99,\n",
    "        help=\"Threshold for matching tracks with detections\",\n",
    "        type=float,\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    heatmap_and_track(\n",
    "        source_weights_path=args.source_weights_path,\n",
    "        source_video_path=args.source_video_path,\n",
    "        target_video_path=args.target_video_path,\n",
    "        confidence_threshold=args.confidence_threshold,\n",
    "        iou_threshold=args.iou_threshold,\n",
    "        heatmap_alpha=args.heatmap_alpha,\n",
    "        radius=args.radius,\n",
    "        track_threshold=args.track_threshold,\n",
    "        track_seconds=args.track_seconds,\n",
    "        match_threshold=args.match_threshold,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
